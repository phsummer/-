通用型验证
1. GPU上先跑通

2. MLU上按照这个步骤：网络功能摸底流程整理

3. mlu版的pytorch镜像：http://yellow.hub.cambricon.com/harbor/projects/30/repositories/daily%2Fx86_64%2Fpytorch

4. mlu版的tensorflow镜像：http://yellow.hub.cambricon.com/harbor/projects/32/repositories/daily%2Fx86_64%2Ftensorflow

精度对比
参数设置相同的情况下，比较训练过程中的loss是否有比较大的差距。

性能对比
指标：fps， 每秒处理的样本数。

fps计算方式：在稳定的epoch下（比如跳过第【0】个epoch，看第【1】个epoch），记录100个iter之间的时间T， fps = 100 * batch_size / T; 或者是第300个iter？

实验环境：GPU V100 (10.100.195.17，8卡， 显存32G)  VS  MLU 370-X8（10.100.146.62/63 ，16卡， 显存24G， EEC  on 的情况下20G（EEC ON））

服务器申请（性能测试时需独占）：没有人使用时需申请，用完需释放。在群里【申请独占：62或者63】和【释放：62或者63】

记录两种情况下的fps：

GPU和MLU上：设置各自的batch_size，占满显存的情况下，记录fps
性能达标要求：MLU的fps >= GPU的fps * 80%（多卡情况），单卡40%
GPU用1中MLU的batch_size，记录其fps
